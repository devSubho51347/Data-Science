{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b527d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce882bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c4f898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "          0.01990842, -0.01764613],\n",
       "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "         -0.06832974, -0.09220405],\n",
       "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "          0.00286377, -0.02593034],\n",
       "        ...,\n",
       "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "         -0.04687948,  0.01549073],\n",
       "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "          0.04452837, -0.02593034],\n",
       "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "         -0.00421986,  0.00306441]]),\n",
       " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "        220.,  57.]),\n",
       " 'frame': None,\n",
       " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)',\n",
       " 'feature_names': ['age',\n",
       "  'sex',\n",
       "  'bmi',\n",
       "  'bp',\n",
       "  's1',\n",
       "  's2',\n",
       "  's3',\n",
       "  's4',\n",
       "  's5',\n",
       "  's6'],\n",
       " 'data_filename': 'diabetes_data.csv.gz',\n",
       " 'target_filename': 'diabetes_target.csv.gz',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0efdcb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes.data\n",
    "Y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39baf8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71a482c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909d2998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f22264",
   "metadata": {},
   "source": [
    "## So the given dataset has 442 rows and each row has 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8853c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "047f28d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd950aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = diabetes.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70b69b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.002592  0.019908 -0.017646  \n",
       "1   -0.039493 -0.068330 -0.092204  \n",
       "2   -0.002592  0.002864 -0.025930  \n",
       "3    0.034309  0.022692 -0.009362  \n",
       "4   -0.002592 -0.031991 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018118  0.044485  \n",
       "439 -0.011080 -0.046879  0.015491  \n",
       "440  0.026560  0.044528 -0.025930  \n",
       "441 -0.039493 -0.004220  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cba84d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us understand the descriptoion of the dataset\n",
    "diabetes.DESCR"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b00ce6e",
   "metadata": {},
   "source": [
    "Y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e323fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00805277",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = np.corrcoef(df, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e864c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d29164d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.DataFrame(corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa34e40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149918</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1   2   3   4         5   6   7         8   9\n",
       "0 NaN       NaN NaN NaN NaN       NaN NaN NaN       NaN NaN\n",
       "1 NaN       NaN NaN NaN NaN  0.142637 NaN NaN  0.149918 NaN\n",
       "2 NaN       NaN NaN NaN NaN       NaN NaN NaN       NaN NaN\n",
       "3 NaN       NaN NaN NaN NaN       NaN NaN NaN       NaN NaN\n",
       "4 NaN       NaN NaN NaN NaN       NaN NaN NaN       NaN NaN\n",
       "5 NaN  0.142637 NaN NaN NaN       NaN NaN NaN       NaN NaN\n",
       "6 NaN       NaN NaN NaN NaN       NaN NaN NaN       NaN NaN\n",
       "7 NaN       NaN NaN NaN NaN       NaN NaN NaN       NaN NaN\n",
       "8 NaN  0.149918 NaN NaN NaN       NaN NaN NaN       NaN NaN\n",
       "9 NaN       NaN NaN NaN NaN       NaN NaN NaN       NaN NaN"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df[(corr_df > 0.1) & (corr_df < 0.15)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe4acf",
   "metadata": {},
   "source": [
    "## Now let us work on the algorithm part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02632ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into train and test\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b8ababe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b6300d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951bbce",
   "metadata": {},
   "source": [
    "### So we observe that 70% of data goes into training and the rest goes into testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53a55418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to import the algorithm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "alg1 = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc89f83d",
   "metadata": {},
   "source": [
    "### Ask the algorithm to learn from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9e0183d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg1.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10e042aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = alg1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5570c32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([163.825036  , 189.71643515, 257.49169266, 212.48350793,\n",
       "       220.57996027, 121.99107209, 150.45170283, 131.82950721,\n",
       "       253.21523344, 219.75046626,  76.49281615, 103.26398337,\n",
       "       143.50996739, 122.4171982 , 161.84116492, 190.81280317,\n",
       "       162.25396678, 233.06967262, 145.93094269, 185.91370344,\n",
       "       137.87382449, 154.85751948, 179.03823811, 170.06684202,\n",
       "       168.11242691, 183.36842165, 166.9493539 , 101.34375187,\n",
       "       152.55801179,  58.84932402, 103.34754841,  95.33212777,\n",
       "       213.93474325, 187.62819647, 114.60756876,  58.95316072,\n",
       "       167.41792547, 117.60999057, 149.30572559, 225.11803474,\n",
       "       162.49782459, 274.50125206,  67.54912978, 161.19652187,\n",
       "       219.92255131, 115.84833338, 220.59491538, 175.04734531,\n",
       "       148.90624877, 123.28681111,  72.43397841,  88.39714524,\n",
       "       224.96701825, 222.19614745, 255.31539335, 180.44014478,\n",
       "       122.73451509, 186.58647797, 135.78351828, 127.85704847,\n",
       "       231.45027588, 226.23240084, 105.77384869, 145.6494443 ,\n",
       "       118.12415963,  67.36571136,  77.05131569, 147.21761785,\n",
       "       183.80641293, 186.64247015,  46.77137714,  89.60536685,\n",
       "        84.96556912, 171.75688107,  88.83515199, 230.72215681,\n",
       "       150.06695116, 150.94582609, 201.54309636, 118.07101019,\n",
       "       174.97246348, 179.4134177 , 115.2241697 ,  78.729143  ,\n",
       "        64.08389657, 155.75037773,  88.72448298, 143.03983465,\n",
       "       175.77220337, 193.57246224,  73.21769882,  65.79666452,\n",
       "       122.47736356, 159.62403741, 165.22963043, 185.31796478,\n",
       "       197.56504618, 228.38567248,  66.10915123, 237.17875178,\n",
       "        73.70044047, 139.62730315, 160.53553736, 149.14161728,\n",
       "        77.47900495,  69.96760163, 135.18937677, 102.08296455,\n",
       "       178.47883403, 121.42487704, 187.81668639])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aab22d",
   "metadata": {},
   "source": [
    "# Compare Y_train and Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "797d3a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.71924016],\n",
       "       [0.71924016, 1.        ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(Y_predicted,\n",
    "            Y_test, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be2ba6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(Y_test,Y_predicted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17616d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.sample(frac = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b06bea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09741fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0503609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6319623210364731"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75910f9",
   "metadata": {},
   "source": [
    "## In order to find the coefficient and intercept of our linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51056e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  11.55660763, -200.94874335,  625.41148264,  241.27528566,\n",
       "       -476.39167297,  265.37163219,  -26.7349982 ,  115.22294473,\n",
       "        557.14181696,   92.5167425 ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd3ad4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.26108961470499"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb636a3",
   "metadata": {},
   "source": [
    "## Let us find the goodness of fit of our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4baaf971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5073451357432066, 0.5107957884445329)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_test = alg1.score(X_test,Y_test)\n",
    "score_train = alg1.score(X_train,Y_train)\n",
    "score_test,score_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21154bbe",
   "metadata": {},
   "source": [
    "### As we can observe that our algorithm quality is pretty average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a2b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
